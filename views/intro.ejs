<%- include('partials/header.ejs') %>

  <nav>
    <ul class="navigation">
      <li><a href="/">AI ASSISTANCE</a></li>
      <li><a href="/intro" class="current">INTRODUCTION</a></li>
      <li><a href="/ML">MACHINE LEARNING</a></li>
      <li><a href="/DL">DEEP LEARNING</a></li>
      <li><a href="/NLP">NLP</a></li>
    </ul>
  </nav>
  
  <header>
    <h1>What is AI (Artificial Intelligence)?</h1>
  </header>
  
  <br>
  <main>
    <time datetime="2024-06-25">Last updated: June 25, 2024</time>
    <br><br>
    <figure>
      <img src="img/1.jpg" alt="AI" width="750" height="500">
    </figure>
    <br><br>
    <div class= "AI_intro">
       <p>Artificial intelligence (AI) refers to a digital computer or computer-controlled robot's capability to perform tasks typically associated with intelligent beings. This concept often involves developing systems that exhibit intellectual processes similar to those of humans. These processes include reasoning, discovering meaning, generalizing, and learning from past experiences.</p>
      <br>
      <p>Since the advent of digital computers in the 1940s, it has been proven that computers can be programmed to execute highly complex tasks. These tasks range from discovering proofs for mathematical theorems to playing chess with remarkable proficiency. However, despite ongoing advancements in computer processing speed and memory capacity, there are still no programs that can match the full flexibility of human intelligence across a broad range of domains or in tasks that require extensive everyday knowledge.</p>
      <br>
      <p>Nonetheless, some AI programs have reached the performance levels of human experts in specific tasks. This form of artificial intelligence, though limited, is utilized in a variety of applications. These include medical diagnosis, computer search engines, voice or handwriting recognition, and chatbots.</p>
      <br>
      <h1>The History of AI</h1>
      <br>
      <p>The concept of "artificial intelligence" finds its origins in the seminal work of Alan Turing and the visionary insights of John McCarthy. While McCarthy coined the term during a 1956 Dartmouth workshop, Turing's 1950 proposition of the "imitation game," later known as the Turing test, laid the groundwork for evaluating machine intelligence. Turing's focus on tasks like language translation and game-playing underscored his belief in the potential of AI to replicate human-like behaviors. McCarthy's workshop marked a pivotal moment, sparking concerted efforts in AI research. MIT physicist Rodney Brooks later delineated the evolutionary stages of AI, commencing with Symbolic AI, which employed logical reasoning akin to human cognition. However, its reliance on manual knowledge encoding and inability to tackle real-world complexity hampered its progress.</p>
      <br>
      <p>Subsequent stages witnessed the emergence of Neural networks, inspired by brain neurons, and their pivotal role in modern AI, thanks to breakthroughs by Geoffrey Hinton and Yann LeCun. Traditional robotics, despite early promise, primarily contributed to niche applications like SLAM algorithms for self-driving cars. Behavior-based robotics, inspired by nature's efficiency, integrated neural networks into robots for problem-solving in dynamic environments. These successive stages underscore AI's evolution from symbolic reasoning to neural network-based learning, mirroring humanity's quest to replicate intelligence in machines.</p>
      <br>
      <h1>Unlocking the Potential of Artificial Intelligence</h1>
      <br>
      <p>Artificial Intelligence (AI) has revolutionized industries worldwide, with its diverse applications reshaping how we interact with technology and solve complex problems. At the forefront of this AI revolution are three key pillars: machine learning, deep learning, and natural language processing (NLP).</p>
      <br>
      <ul class="AI_applications">
        <li><strong>Machine Learning:</strong> Machine learning algorithms lie at the heart of AI's capabilities, empowering systems to learn from data and make decisions without explicit programming. From predicting consumer behavior in marketing to diagnosing diseases in healthcare, machine learning has enabled unprecedented insights and efficiencies across various sectors.<br></li>
        <li><strong>Deep Learning:</strong> A subset of machine learning, deep learning employs neural networks with multiple layers to analyze complex data. This technology has propelled breakthroughs in image and speech recognition, autonomous vehicles, and medical diagnostics, pushing the boundaries of what AI can achieve in terms of understanding and interpreting intricate patterns in data.<br></li>
        <li><strong>Natural Language Processing (NLP):</strong> NLP enables machines to understand, interpret, and generate human language, facilitating seamless human-computer interaction. From virtual assistants like Siri and Alexa to sentiment analysis tools and language translation services, NLP has revolutionized communication and information retrieval, making AI more accessible and intuitive for users worldwide.</li>
      </ul>
    </div>
  </main>
  <br>
  <section id="references">
    <em>Articles referenced:</em>
    <ol class="Articles">
      <li><a href="https://www.britannica.com/technology/artificial-intelligence/Nouvelle-AI">"artificial intelligence," April 3, 2024, BJ.Copeland </a></li>
      <li><a href="https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai">"What is AI (artificial intelligence)?," June 24, 2024, McKinsey & Company, </a></li>
    </ol>
  </section>
  <br><br>
    
<%- include('partials/footer.ejs') %>